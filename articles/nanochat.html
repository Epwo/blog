<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><link rel="preload" href="https://ph-files.imgix.net/36810de6-302c-443a-90f3-763a9757fc01.png?auto=format&amp;fit=crop" as="image" data-next-head=""/><link rel="preload" href="/blog/_next/static/media/4cf2300e9c8272f7-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/blog/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/blog/_next/static/css/1f148c948bb4c78d.css" as="style"/><link rel="preload" href="/blog/_next/static/css/1cb85b1c355f1fa8.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/1f148c948bb4c78d.css" data-n-g=""/><link rel="stylesheet" href="/blog/_next/static/css/1cb85b1c355f1fa8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/blog/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/blog/_next/static/chunks/webpack-8b8747d91b84f23b.js" defer=""></script><script src="/blog/_next/static/chunks/framework-2f335d22a7318891.js" defer=""></script><script src="/blog/_next/static/chunks/main-dad8c2de6c2b05ba.js" defer=""></script><script src="/blog/_next/static/chunks/pages/_app-5490ad400bc1e6e8.js" defer=""></script><script src="/blog/_next/static/chunks/996-169541a85194d51f.js" defer=""></script><script src="/blog/_next/static/chunks/476-39bbd294c5186124.js" defer=""></script><script src="/blog/_next/static/chunks/pages/articles/%5Bslug%5D-d0a68914715baca5.js" defer=""></script><script src="/blog/_next/static/BtaXky80g4SKgGkllXjpG/_buildManifest.js" defer=""></script><script src="/blog/_next/static/BtaXky80g4SKgGkllXjpG/_ssgManifest.js" defer=""></script></head><body><link rel="preload" as="image" href="https://ph-files.imgix.net/36810de6-302c-443a-90f3-763a9757fc01.png?auto=format&amp;fit=crop"/><div id="__next"><main class="__variable_7ddc9d __variable_130274"><div class="HeaderImage_headerImageContainer__Khgdd"><div class="HeaderImage_imageWrapper__naSNh"><img alt="Header image for potichat (nanochat) - lets remake chatgpt ?!" decoding="async" data-nimg="fill" class="HeaderImage_headerImage__T4YXT" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="https://ph-files.imgix.net/36810de6-302c-443a-90f3-763a9757fc01.png?auto=format&amp;fit=crop"/><div class="HeaderImage_imageFadeOverlay__B1Dny"></div></div></div><div class="ArticleNavBar_navBar__XXLij"><div class="ArticleNavBar_navBarContent__OnqKO"><a class="ArticleNavBar_backButton__DnCpY" href="/blog"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left" aria-hidden="true"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg></a><div class="ArticleNavBar_breadcrumbs__3EEIn"><a class="ArticleNavBar_breadcrumbItem__leJnr" href="/blog">Home</a><span class="ArticleNavBar_breadcrumbSeparator__NYFW8">/</span><span class="ArticleNavBar_breadcrumbCurrent__Syolk">potichat (nanochat) - lets remake chatgpt ?!</span></div></div></div><article class="page_articleDetail___FGo1"><div class="page_articleHeader__ZEI9R"><h1>potichat (nanochat) - lets remake chatgpt ?!</h1><div class="page_articleMeta__eG2iP"><p class="page_date__EZD2O"></p><span class="ThemeTag_themeTag__xXwtj"><span class="ThemeTag_themeTagContent__NqEtM"><span class="ThemeTag_emoji__a5dW3">ðŸ’»</span>Coding</span><span class="ThemeTag_themeTagContent__NqEtM"><span class="ThemeTag_emoji__a5dW3">ðŸ§ </span>ML</span></span></div><p class="page_summary__g9kyb">making a chatgpt like from scratch to naviguate the whole stack</p></div><p>Inspired by karapathy&#x27;s awesome blog post about nanochat, and then followed by the ppl from hugging face.
I will try to train an LLM from scratch, to better understand the ins and outs.
I will be following HF&#x27;s free course at first <a href="https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook#super-power-speed-and-data">you can find it here</a></p>
<h1>Starting</h1>
<h2>The architecture type.</h2>
<p>I&#x27;ve chosen to take the same baseline as google&#x27;s Gemma or Alibaba&#x27;s Qwen or even HF&#x27;s SmolLM.
The architecture baseline will be <em>Dense</em>. I&#x27;ve Chosen to go with this one rather than an MOE or hybrid because of the final size and parameters of the model.
I still would like to avoid training a 400B model, because it will take too much time, and therefore would be too costy for an experiment (and because I&#x27;m impatient :p)
So Let&#x27;s aim for a &gt;10B model.</p>
<h2>The training framework</h2>
<p>In the same spirit as before, I&#x27;ve chosen to go with <strong>TorchTitan</strong> (<a href="">here</a>) because while It was only tested by the pytorch team and is relatively new, It is optimized for Dense type.
It is also much lighter, and therefore (I hope) will take me less time to go through if needed.</p>
<p><em>WIP</em></p></article></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"article":{"title":"potichat (nanochat) - lets remake chatgpt ?!","date":"2025-16-10","content":"\nInspired by karapathy's awesome blog post about nanochat, and then followed by the ppl from hugging face.\nI will try to train an LLM from scratch, to better understand the ins and outs.\nI will be following HF's free course at first [you can find it here](https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook#super-power-speed-and-data)\n\n# Starting\n\n## The architecture type.\n\nI've chosen to take the same baseline as google's Gemma or Alibaba's Qwen or even HF's SmolLM.\nThe architecture baseline will be _Dense_. I've Chosen to go with this one rather than an MOE or hybrid because of the final size and parameters of the model.\nI still would like to avoid training a 400B model, because it will take too much time, and therefore would be too costy for an experiment (and because I'm impatient :p)\nSo Let's aim for a \u003e10B model.\n\n## The training framework\n\nIn the same spirit as before, I've chosen to go with **TorchTitan** ([here]([https://github.com/pytorch/torchtitan)) because while It was only tested by the pytorch team and is relatively new, It is optimized for Dense type.\nIt is also much lighter, and therefore (I hope) will take me less time to go through if needed.\n\n_WIP_\n","image":"https://ph-files.imgix.net/36810de6-302c-443a-90f3-763a9757fc01.png?auto=format\u0026fit=crop","theme":"Coding,ML","summary":"making a chatgpt like from scratch to naviguate the whole stack"}},"__N_SSG":true},"page":"/articles/[slug]","query":{"slug":"nanochat"},"buildId":"BtaXky80g4SKgGkllXjpG","assetPrefix":"/blog","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>